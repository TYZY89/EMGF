{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"12oXL0I2knYoVGIDT-8IV4bwIL0EtWeOJ","authorship_tag":"ABX9TyPSJMpM5uyBJ6lLiPJp0rjY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"i6thvsOGza96","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699417935891,"user_tz":-480,"elapsed":663,"user":{"displayName":"zhou yong","userId":"17408050396047199167"}},"outputId":"40e9c1e6-37d9-4c06-d27a-a4f643eda1ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab/EMGF_NEW\n"]}],"source":["cd /content/drive/MyDrive/Colab/EMGF_NEW"]},{"cell_type":"code","source":["!pip install -r requirements.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rZ91qjY_Nbcw","executionInfo":{"status":"ok","timestamp":1699417953858,"user_tz":-480,"elapsed":17332,"user":{"displayName":"zhou yong","userId":"17408050396047199167"}},"outputId":"ce4561e6-9b1c-431c-f5b2-bed46ec26bd1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.1.0+cu118)\n","Collecting transformers==4.34.1 (from -r requirements.txt (line 2))\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch_geometric==2.4.0 (from -r requirements.txt (line 3))\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pytorch_metric_learning==2.3.0 (from -r requirements.txt (line 4))\n","  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting supar==1.1.4 (from -r requirements.txt (line 5))\n","  Downloading supar-1.1.4-py3-none-any.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboardX==2.6.2.2 (from -r requirements.txt (line 6))\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 1)) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 1)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 1)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 1)) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 1)) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 1)) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->-r requirements.txt (line 1)) (2.1.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.34.1->-r requirements.txt (line 2))\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->-r requirements.txt (line 2)) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->-r requirements.txt (line 2)) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->-r requirements.txt (line 2)) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->-r requirements.txt (line 2)) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->-r requirements.txt (line 2)) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers==4.34.1->-r requirements.txt (line 2))\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.34.1->-r requirements.txt (line 2))\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.1->-r requirements.txt (line 2)) (4.66.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0->-r requirements.txt (line 3)) (1.11.3)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0->-r requirements.txt (line 3)) (3.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0->-r requirements.txt (line 3)) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric==2.4.0->-r requirements.txt (line 3)) (5.9.5)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from supar==1.1.4->-r requirements.txt (line 5)) (3.8.1)\n","Collecting stanza (from supar==1.1.4->-r requirements.txt (line 5))\n","  Downloading stanza-1.6.1-py3-none-any.whl (881 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m881.2/881.2 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill (from supar==1.1.4->-r requirements.txt (line 5))\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX==2.6.2.2->-r requirements.txt (line 6)) (3.20.3)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.34.1->-r requirements.txt (line 2))\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->-r requirements.txt (line 1)) (2.1.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->supar==1.1.4->-r requirements.txt (line 5)) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->supar==1.1.4->-r requirements.txt (line 5)) (1.3.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.1->-r requirements.txt (line 2)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.1->-r requirements.txt (line 2)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.1->-r requirements.txt (line 2)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.34.1->-r requirements.txt (line 2)) (2023.7.22)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric==2.4.0->-r requirements.txt (line 3)) (3.2.0)\n","Collecting emoji (from stanza->supar==1.1.4->-r requirements.txt (line 5))\n","  Downloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->-r requirements.txt (line 1)) (1.3.0)\n","Installing collected packages: tensorboardX, safetensors, emoji, dill, huggingface-hub, torch_geometric, tokenizers, stanza, pytorch_metric_learning, transformers, supar\n","Successfully installed dill-0.3.7 emoji-2.8.0 huggingface-hub-0.17.3 pytorch_metric_learning-2.3.0 safetensors-0.4.0 stanza-1.6.1 supar-1.1.4 tensorboardX-2.6.2.2 tokenizers-0.14.1 torch_geometric-2.4.0 transformers-4.34.1\n"]}]},{"cell_type":"code","source":["!sh run.sh"],"metadata":{"id":"u7UUivo9sO86","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b0ea38b2-5554-4f83-c9e2-0d8d3f888671","executionInfo":{"status":"ok","timestamp":1699423544186,"user_tz":-480,"elapsed":5589549,"user":{"displayName":"zhou yong","userId":"17408050396047199167"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["choice cuda:0\n","Downloading (…)okenizer_config.json: 100% 28.0/28.0 [00:00<00:00, 109kB/s]\n","Downloading (…)solve/main/vocab.txt: 100% 232k/232k [00:00<00:00, 42.5MB/s]\n","Downloading (…)/main/tokenizer.json: 100% 466k/466k [00:00<00:00, 43.8MB/s]\n","Downloading (…)lve/main/config.json: 100% 570/570 [00:00<00:00, 2.35MB/s]\n","Downloading model.safetensors: 100% 440M/440M [00:01<00:00, 281MB/s]\n","n_trainable_params: 145001478, n_nontrainable_params: 12209200\n","training arguments:\n",">>> model_name: EHFB\n",">>> dataset: restaurant\n",">>> optimizer: <class 'torch.optim.adam.Adam'>\n",">>> initializer: <function xavier_uniform_ at 0x7d832d19fd00>\n",">>> l2reg: 0.0001\n",">>> num_epoch: 20\n",">>> batch_size: 16\n",">>> log_step: 5\n",">>> embed_dim: 300\n",">>> num_layers: 2\n",">>> polarities_dim: 3\n",">>> gcn_dropout: 0.1\n",">>> attention_heads: 1\n",">>> max_length: 100\n",">>> device: cuda\n",">>> seed: 1000\n",">>> weight_decay: 0.0001\n",">>> vocab_dir: ./dataset/Restaurants_corenlp\n",">>> pad_id: 0\n",">>> cuda: 0\n",">>> gamma: 1.0\n",">>> theta: 0.12\n",">>> pretrained_bert_name: bert-base-uncased\n",">>> adam_epsilon: 1e-08\n",">>> bert_dim: 768\n",">>> hidden_dim: 768\n",">>> bert_dropout: 0.3\n",">>> bert_lr: 2e-05\n",">>> dep_size: 384\n",">>> lower: True\n",">>> special_token: [N]\n",">>> max_num_spans: 3\n",">>> syn_condition: con_and_dep\n",">>> dim_w: 768\n",">>> lstm_dim: 384\n",">>> is_bert: 1\n",">>> dim_k: 400\n",">>> dropout_rate: 0.5\n",">>> fusion_condition: ResEMFH\n",">>> dep_layers: 3\n",">>> sem_layers: 9\n",">>> high_order: True\n",">>> hidden_size: 512\n",">>> dropout_r: 0.1\n",">>> n_layers: 2\n",">>> model_class: <class 'models.models.EHFBClassifier'>\n",">>> dataset_file: {'train': './dataset/Restaurants_corenlp/train_new.json', 'test': './dataset/Restaurants_corenlp/test_new.json'}\n","bert learning rate on\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 0\n","We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.6489_f1_0.2623\n","loss: 1.1107, acc: 0.6667, test_acc: 0.6489, f1: 0.2623\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.6525_f1_0.2632\n","loss: 1.1413, acc: 0.6333, test_acc: 0.6525, f1: 0.2632\n","loss: 1.1057, acc: 0.6386, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0797, acc: 0.6637, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0760, acc: 0.6736, test_acc: 0.6525, f1: 0.2632\n","loss: 1.1147, acc: 0.6171, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0678, acc: 0.6157, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0822, acc: 0.6057, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0698, acc: 0.6007, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0582, acc: 0.6013, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0219, acc: 0.6116, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0423, acc: 0.6143, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0413, acc: 0.6152, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0445, acc: 0.6137, test_acc: 0.6525, f1: 0.2632\n","loss: 1.1076, acc: 0.5884, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0653, acc: 0.5837, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0179, acc: 0.5894, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0205, acc: 0.5912, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0323, acc: 0.5909, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0191, acc: 0.5907, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0244, acc: 0.5886, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0467, acc: 0.5850, test_acc: 0.6525, f1: 0.2632\n","loss: 0.9872, acc: 0.5878, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0603, acc: 0.5832, test_acc: 0.6525, f1: 0.2632\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 1\n","loss: 1.0423, acc: 0.5217, test_acc: 0.6525, f1: 0.2632\n","loss: 0.9747, acc: 0.6364, test_acc: 0.6525, f1: 0.2632\n","loss: 0.9862, acc: 0.6316, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0222, acc: 0.6250, test_acc: 0.6525, f1: 0.2632\n","loss: 1.1254, acc: 0.5608, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0296, acc: 0.5600, test_acc: 0.6525, f1: 0.2632\n","loss: 0.9759, acc: 0.5777, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0983, acc: 0.5532, test_acc: 0.6525, f1: 0.2632\n","loss: 0.9596, acc: 0.5659, test_acc: 0.6525, f1: 0.2632\n","loss: 0.9327, acc: 0.5868, test_acc: 0.6525, f1: 0.2632\n","loss: 0.9125, acc: 0.6038, test_acc: 0.6525, f1: 0.2632\n","loss: 0.9734, acc: 0.6074, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0121, acc: 0.6073, test_acc: 0.6525, f1: 0.2632\n","loss: 0.9592, acc: 0.6122, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0013, acc: 0.6105, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0003, acc: 0.6072, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0199, acc: 0.6040, test_acc: 0.6525, f1: 0.2632\n","loss: 0.9609, acc: 0.6072, test_acc: 0.6525, f1: 0.2632\n","loss: 0.9302, acc: 0.6116, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0572, acc: 0.6034, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0298, acc: 0.5984, test_acc: 0.6525, f1: 0.2632\n","loss: 0.9658, acc: 0.6000, test_acc: 0.6525, f1: 0.2632\n","loss: 0.9476, acc: 0.6009, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0480, acc: 0.5951, test_acc: 0.6525, f1: 0.2632\n","loss: 1.0192, acc: 0.5919, test_acc: 0.6525, f1: 0.2632\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 2\n","loss: 0.9249, acc: 0.6667, test_acc: 0.6525, f1: 0.2632\n","loss: 0.9112, acc: 0.6667, test_acc: 0.6525, f1: 0.2632\n","loss: 0.9420, acc: 0.6593, test_acc: 0.6525, f1: 0.2632\n","loss: 0.9745, acc: 0.6341, test_acc: 0.6525, f1: 0.2632\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.6615_f1_0.2979\n","loss: 0.9062, acc: 0.6387, test_acc: 0.6615, f1: 0.2979\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.7285_f1_0.4666\n","loss: 0.8984, acc: 0.6519, test_acc: 0.7285, f1: 0.4666\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.7701_f1_0.5306\n","loss: 0.9332, acc: 0.6542, test_acc: 0.7701, f1: 0.5306\n","loss: 0.9829, acc: 0.6408, test_acc: 0.7575, f1: 0.5154\n","loss: 1.0086, acc: 0.6277, test_acc: 0.7665, f1: 0.5263\n","loss: 0.8653, acc: 0.6415, test_acc: 0.7520, f1: 0.5074\n","loss: 0.9594, acc: 0.6337, test_acc: 0.7575, f1: 0.5102\n","loss: 0.8572, acc: 0.6415, test_acc: 0.7502, f1: 0.5172\n","loss: 0.8845, acc: 0.6482, test_acc: 0.7611, f1: 0.5248\n","loss: 0.7568, acc: 0.6643, test_acc: 0.7511, f1: 0.5136\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.7819_f1_0.5636\n","loss: 0.8951, acc: 0.6711, test_acc: 0.7819, f1: 0.5636\n","loss: 0.8675, acc: 0.6695, test_acc: 0.7765, f1: 0.5548\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.7900_f1_0.6137\n","loss: 0.9438, acc: 0.6726, test_acc: 0.7900, f1: 0.6137\n","loss: 0.8815, acc: 0.6780, test_acc: 0.7900, f1: 0.6059\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.7910_f1_0.6180\n","loss: 0.8571, acc: 0.6831, test_acc: 0.7910, f1: 0.6180\n","loss: 0.9072, acc: 0.6845, test_acc: 0.7828, f1: 0.5822\n","loss: 1.0033, acc: 0.6757, test_acc: 0.7656, f1: 0.5489\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8009_f1_0.6521\n","loss: 0.8143, acc: 0.6825, test_acc: 0.8009, f1: 0.6521\n","loss: 0.8386, acc: 0.6876, test_acc: 0.7982, f1: 0.6343\n","loss: 0.7858, acc: 0.6941, test_acc: 0.7973, f1: 0.6321\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 3\n","loss: 0.6993, acc: 0.9697, test_acc: 0.7900, f1: 0.5857\n","loss: 0.8018, acc: 0.9194, test_acc: 0.7864, f1: 0.5832\n","loss: 0.7623, acc: 0.8925, test_acc: 0.7919, f1: 0.6091\n","loss: 0.8252, acc: 0.8710, test_acc: 0.7882, f1: 0.6129\n","loss: 0.8006, acc: 0.8609, test_acc: 0.7855, f1: 0.6168\n","loss: 0.7604, acc: 0.8531, test_acc: 0.7665, f1: 0.6127\n","loss: 0.8114, acc: 0.8522, test_acc: 0.7919, f1: 0.6358\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8063_f1_0.6440\n","loss: 0.8482, acc: 0.8348, test_acc: 0.8063, f1: 0.6440\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8109_f1_0.6738\n","loss: 0.7748, acc: 0.8321, test_acc: 0.8109, f1: 0.6738\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8217_f1_0.7282\n","loss: 0.7090, acc: 0.8407, test_acc: 0.8217, f1: 0.7282\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8244_f1_0.7109\n","loss: 0.8063, acc: 0.8380, test_acc: 0.8244, f1: 0.7109\n","loss: 0.7920, acc: 0.8343, test_acc: 0.8127, f1: 0.6557\n","loss: 0.6680, acc: 0.8417, test_acc: 0.8217, f1: 0.6804\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8262_f1_0.7015\n","loss: 0.8818, acc: 0.8260, test_acc: 0.8262, f1: 0.7015\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8398_f1_0.7483\n","loss: 0.8354, acc: 0.8238, test_acc: 0.8398, f1: 0.7483\n","loss: 0.7447, acc: 0.8233, test_acc: 0.8326, f1: 0.7217\n","loss: 0.7380, acc: 0.8277, test_acc: 0.8290, f1: 0.6996\n","loss: 0.7054, acc: 0.8293, test_acc: 0.8299, f1: 0.7193\n","loss: 0.6936, acc: 0.8345, test_acc: 0.8326, f1: 0.7201\n","loss: 0.7093, acc: 0.8372, test_acc: 0.8262, f1: 0.6967\n","loss: 0.6710, acc: 0.8404, test_acc: 0.8244, f1: 0.6971\n","loss: 0.8183, acc: 0.8368, test_acc: 0.8308, f1: 0.7306\n","loss: 0.7482, acc: 0.8374, test_acc: 0.8299, f1: 0.7476\n","loss: 0.6715, acc: 0.8388, test_acc: 0.8380, f1: 0.7452\n","loss: 0.7402, acc: 0.8373, test_acc: 0.8271, f1: 0.7084\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 4\n","loss: 0.7164, acc: 0.9167, test_acc: 0.8199, f1: 0.7068\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8425_f1_0.7492\n","loss: 0.6749, acc: 0.9091, test_acc: 0.8425, f1: 0.7492\n","loss: 0.6829, acc: 0.9125, test_acc: 0.8344, f1: 0.7255\n","loss: 0.6559, acc: 0.9238, test_acc: 0.8217, f1: 0.6906\n","loss: 0.6440, acc: 0.9191, test_acc: 0.8208, f1: 0.6838\n","loss: 0.7541, acc: 0.8970, test_acc: 0.8335, f1: 0.7339\n","loss: 0.7789, acc: 0.8756, test_acc: 0.8362, f1: 0.7615\n","loss: 0.7992, acc: 0.8598, test_acc: 0.8389, f1: 0.7526\n","loss: 0.6289, acc: 0.8672, test_acc: 0.8281, f1: 0.7287\n","loss: 0.6310, acc: 0.8727, test_acc: 0.8253, f1: 0.7108\n","loss: 0.7939, acc: 0.8630, test_acc: 0.8308, f1: 0.7239\n","loss: 0.7177, acc: 0.8660, test_acc: 0.8335, f1: 0.7424\n","loss: 0.6453, acc: 0.8721, test_acc: 0.8262, f1: 0.7364\n","loss: 0.6030, acc: 0.8797, test_acc: 0.8281, f1: 0.7366\n","loss: 0.6884, acc: 0.8790, test_acc: 0.8290, f1: 0.7367\n","loss: 0.7531, acc: 0.8693, test_acc: 0.8281, f1: 0.7304\n","loss: 0.6563, acc: 0.8758, test_acc: 0.8362, f1: 0.7466\n","loss: 0.8007, acc: 0.8707, test_acc: 0.8290, f1: 0.7437\n","loss: 0.7485, acc: 0.8687, test_acc: 0.8416, f1: 0.7634\n","loss: 0.6570, acc: 0.8725, test_acc: 0.8136, f1: 0.6881\n","loss: 0.5816, acc: 0.8735, test_acc: 0.8136, f1: 0.6921\n","loss: 0.6396, acc: 0.8742, test_acc: 0.8389, f1: 0.7720\n","loss: 0.6774, acc: 0.8738, test_acc: 0.8398, f1: 0.7785\n","loss: 0.6800, acc: 0.8759, test_acc: 0.8199, f1: 0.6992\n","loss: 0.5865, acc: 0.8793, test_acc: 0.8208, f1: 0.6910\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 5\n","loss: 0.6633, acc: 0.8571, test_acc: 0.8335, f1: 0.7402\n","loss: 0.6167, acc: 0.9000, test_acc: 0.8425, f1: 0.7531\n","loss: 0.6261, acc: 0.9000, test_acc: 0.8054, f1: 0.6796\n","loss: 0.6922, acc: 0.9000, test_acc: 0.8118, f1: 0.6955\n","loss: 0.6516, acc: 0.8873, test_acc: 0.8425, f1: 0.7527\n","loss: 0.6700, acc: 0.8947, test_acc: 0.8353, f1: 0.7568\n","loss: 0.6000, acc: 0.9000, test_acc: 0.8335, f1: 0.7499\n","loss: 0.6302, acc: 0.9027, test_acc: 0.8362, f1: 0.7370\n","loss: 0.7446, acc: 0.8867, test_acc: 0.8416, f1: 0.7522\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8516_f1_0.7710\n","loss: 0.5771, acc: 0.8881, test_acc: 0.8516, f1: 0.7710\n","loss: 0.6082, acc: 0.8885, test_acc: 0.8489, f1: 0.7645\n","loss: 0.5925, acc: 0.8957, test_acc: 0.8480, f1: 0.7601\n","loss: 0.6431, acc: 0.8925, test_acc: 0.8326, f1: 0.7164\n","loss: 0.5863, acc: 0.9005, test_acc: 0.8235, f1: 0.6907\n","loss: 0.6521, acc: 0.8981, test_acc: 0.8344, f1: 0.7241\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8534_f1_0.7760\n","loss: 0.7315, acc: 0.8927, test_acc: 0.8534, f1: 0.7760\n","loss: 0.5643, acc: 0.8954, test_acc: 0.8525, f1: 0.7658\n","loss: 0.6291, acc: 0.8942, test_acc: 0.8425, f1: 0.7448\n","loss: 0.6002, acc: 0.8909, test_acc: 0.8525, f1: 0.7781\n","loss: 0.6955, acc: 0.8924, test_acc: 0.8489, f1: 0.7767\n","loss: 0.5428, acc: 0.8980, test_acc: 0.8425, f1: 0.7542\n","loss: 0.5810, acc: 0.8981, test_acc: 0.8480, f1: 0.7672\n","loss: 0.8091, acc: 0.8917, test_acc: 0.8317, f1: 0.7514\n","loss: 0.4850, acc: 0.8964, test_acc: 0.8443, f1: 0.7503\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 6\n","loss: 0.5906, acc: 0.9310, test_acc: 0.8290, f1: 0.7104\n","loss: 0.4990, acc: 0.9455, test_acc: 0.8344, f1: 0.7264\n","loss: 0.6187, acc: 0.9375, test_acc: 0.8389, f1: 0.7607\n","loss: 0.5676, acc: 0.9423, test_acc: 0.8462, f1: 0.7723\n","loss: 0.5265, acc: 0.9407, test_acc: 0.8389, f1: 0.7430\n","loss: 0.6242, acc: 0.9264, test_acc: 0.8362, f1: 0.7417\n","loss: 0.5911, acc: 0.9206, test_acc: 0.8489, f1: 0.7659\n","loss: 0.5788, acc: 0.9167, test_acc: 0.8443, f1: 0.7556\n","loss: 0.5790, acc: 0.9132, test_acc: 0.8498, f1: 0.7751\n","loss: 0.5184, acc: 0.9213, test_acc: 0.8462, f1: 0.7735\n","loss: 0.5657, acc: 0.9223, test_acc: 0.8380, f1: 0.7571\n","loss: 0.6873, acc: 0.9116, test_acc: 0.8407, f1: 0.7665\n","loss: 0.5577, acc: 0.9157, test_acc: 0.8434, f1: 0.7652\n","loss: 0.5892, acc: 0.9191, test_acc: 0.8471, f1: 0.7680\n","loss: 0.5334, acc: 0.9231, test_acc: 0.8516, f1: 0.7713\n","loss: 0.5689, acc: 0.9229, test_acc: 0.8489, f1: 0.7641\n","loss: 0.5418, acc: 0.9277, test_acc: 0.8416, f1: 0.7624\n","loss: 0.5490, acc: 0.9280, test_acc: 0.8471, f1: 0.7782\n","loss: 0.5151, acc: 0.9287, test_acc: 0.8489, f1: 0.7798\n","loss: 0.4886, acc: 0.9310, test_acc: 0.8425, f1: 0.7550\n","loss: 0.5306, acc: 0.9290, test_acc: 0.8443, f1: 0.7454\n","loss: 0.5460, acc: 0.9292, test_acc: 0.8380, f1: 0.7319\n","loss: 0.4964, acc: 0.9310, test_acc: 0.8471, f1: 0.7630\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8615_f1_0.8011\n","loss: 0.5685, acc: 0.9323, test_acc: 0.8615, f1: 0.8011\n","loss: 0.6180, acc: 0.9304, test_acc: 0.8579, f1: 0.7865\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 7\n","loss: 0.4673, acc: 1.0000, test_acc: 0.8561, f1: 0.7835\n","loss: 0.5351, acc: 0.9630, test_acc: 0.8543, f1: 0.7845\n","loss: 0.5725, acc: 0.9643, test_acc: 0.8579, f1: 0.7898\n","loss: 0.5633, acc: 0.9550, test_acc: 0.8579, f1: 0.7870\n","loss: 0.4967, acc: 0.9580, test_acc: 0.8588, f1: 0.7797\n","loss: 0.5419, acc: 0.9543, test_acc: 0.8606, f1: 0.7907\n","loss: 0.5779, acc: 0.9363, test_acc: 0.8561, f1: 0.7778\n","loss: 0.5285, acc: 0.9348, test_acc: 0.8552, f1: 0.7761\n","loss: 0.4874, acc: 0.9368, test_acc: 0.8480, f1: 0.7568\n","loss: 0.4378, acc: 0.9435, test_acc: 0.8471, f1: 0.7577\n","loss: 0.5107, acc: 0.9459, test_acc: 0.8480, f1: 0.7636\n","loss: 0.4568, acc: 0.9500, test_acc: 0.8516, f1: 0.7765\n","loss: 0.5759, acc: 0.9457, test_acc: 0.8489, f1: 0.7765\n","loss: 0.4494, acc: 0.9471, test_acc: 0.8543, f1: 0.7801\n","loss: 0.4370, acc: 0.9509, test_acc: 0.8543, f1: 0.7707\n","loss: 0.5106, acc: 0.9512, test_acc: 0.8498, f1: 0.7610\n","loss: 0.6215, acc: 0.9478, test_acc: 0.8615, f1: 0.7975\n","loss: 0.6291, acc: 0.9435, test_acc: 0.8543, f1: 0.7825\n","loss: 0.5893, acc: 0.9390, test_acc: 0.8552, f1: 0.7838\n","loss: 0.4877, acc: 0.9401, test_acc: 0.8434, f1: 0.7587\n","loss: 0.5411, acc: 0.9382, test_acc: 0.8443, f1: 0.7564\n","loss: 0.4483, acc: 0.9394, test_acc: 0.8498, f1: 0.7706\n","loss: 0.4765, acc: 0.9413, test_acc: 0.8452, f1: 0.7686\n","loss: 0.5621, acc: 0.9383, test_acc: 0.8471, f1: 0.7796\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 8\n","loss: 0.3888, acc: 1.0000, test_acc: 0.8507, f1: 0.7837\n","loss: 0.3866, acc: 1.0000, test_acc: 0.8425, f1: 0.7591\n","loss: 0.4583, acc: 1.0000, test_acc: 0.8416, f1: 0.7549\n","loss: 0.5098, acc: 0.9904, test_acc: 0.8507, f1: 0.7760\n","loss: 0.4992, acc: 0.9774, test_acc: 0.8507, f1: 0.7778\n","loss: 0.4287, acc: 0.9771, test_acc: 0.8543, f1: 0.7792\n","loss: 0.4631, acc: 0.9802, test_acc: 0.8507, f1: 0.7705\n","loss: 0.6176, acc: 0.9652, test_acc: 0.8498, f1: 0.7623\n","loss: 0.3855, acc: 0.9691, test_acc: 0.8534, f1: 0.7830\n","loss: 0.5385, acc: 0.9626, test_acc: 0.8498, f1: 0.7812\n","loss: 0.4756, acc: 0.9595, test_acc: 0.8507, f1: 0.7770\n","loss: 0.5560, acc: 0.9513, test_acc: 0.8516, f1: 0.7725\n","loss: 0.4476, acc: 0.9550, test_acc: 0.8462, f1: 0.7596\n","loss: 0.4241, acc: 0.9556, test_acc: 0.8398, f1: 0.7335\n","loss: 0.5003, acc: 0.9541, test_acc: 0.8543, f1: 0.7707\n","loss: 0.4530, acc: 0.9546, test_acc: 0.8471, f1: 0.7662\n","loss: 0.4845, acc: 0.9533, test_acc: 0.8452, f1: 0.7646\n","loss: 0.5221, acc: 0.9505, test_acc: 0.8534, f1: 0.7784\n","loss: 0.3853, acc: 0.9526, test_acc: 0.8489, f1: 0.7698\n","loss: 0.4721, acc: 0.9533, test_acc: 0.8452, f1: 0.7515\n","loss: 0.4845, acc: 0.9560, test_acc: 0.8489, f1: 0.7555\n","loss: 0.4165, acc: 0.9567, test_acc: 0.8543, f1: 0.7785\n","loss: 0.4552, acc: 0.9588, test_acc: 0.8471, f1: 0.7761\n","loss: 0.3936, acc: 0.9604, test_acc: 0.8498, f1: 0.7710\n","loss: 0.5045, acc: 0.9595, test_acc: 0.8407, f1: 0.7499\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 9\n","loss: 0.5396, acc: 0.9459, test_acc: 0.8543, f1: 0.7758\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8624_f1_0.7984\n","loss: 0.4602, acc: 0.9538, test_acc: 0.8624, f1: 0.7984\n","loss: 0.5291, acc: 0.9468, test_acc: 0.8624, f1: 0.8053\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8706_f1_0.8103\n","loss: 0.4844, acc: 0.9444, test_acc: 0.8706, f1: 0.8103\n","loss: 0.4801, acc: 0.9484, test_acc: 0.8498, f1: 0.7672\n","loss: 0.6416, acc: 0.9389, test_acc: 0.8434, f1: 0.7484\n","loss: 0.4017, acc: 0.9476, test_acc: 0.8416, f1: 0.7504\n","loss: 0.3950, acc: 0.9504, test_acc: 0.8344, f1: 0.7398\n","loss: 0.4070, acc: 0.9559, test_acc: 0.8380, f1: 0.7448\n","loss: 0.5783, acc: 0.9468, test_acc: 0.8443, f1: 0.7594\n","loss: 0.3518, acc: 0.9511, test_acc: 0.8443, f1: 0.7622\n","loss: 0.3871, acc: 0.9543, test_acc: 0.8452, f1: 0.7684\n","loss: 0.4131, acc: 0.9582, test_acc: 0.8489, f1: 0.7739\n","loss: 0.4180, acc: 0.9588, test_acc: 0.8462, f1: 0.7633\n","loss: 0.4569, acc: 0.9592, test_acc: 0.8398, f1: 0.7489\n","loss: 0.5259, acc: 0.9550, test_acc: 0.8552, f1: 0.7831\n","loss: 0.4919, acc: 0.9519, test_acc: 0.8552, f1: 0.7926\n","loss: 0.3758, acc: 0.9534, test_acc: 0.8561, f1: 0.7919\n","loss: 0.4108, acc: 0.9555, test_acc: 0.8597, f1: 0.7986\n","loss: 0.4343, acc: 0.9565, test_acc: 0.8606, f1: 0.7997\n","loss: 0.4013, acc: 0.9567, test_acc: 0.8525, f1: 0.7814\n","loss: 0.3951, acc: 0.9583, test_acc: 0.8507, f1: 0.7780\n","loss: 0.4711, acc: 0.9582, test_acc: 0.8507, f1: 0.7764\n","loss: 0.4070, acc: 0.9597, test_acc: 0.8534, f1: 0.7852\n","loss: 0.3961, acc: 0.9611, test_acc: 0.8543, f1: 0.7915\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 10\n","loss: 0.4280, acc: 0.9722, test_acc: 0.8570, f1: 0.7955\n","loss: 0.3996, acc: 0.9710, test_acc: 0.8534, f1: 0.7863\n","loss: 0.4350, acc: 0.9697, test_acc: 0.8462, f1: 0.7615\n","loss: 0.4570, acc: 0.9597, test_acc: 0.8416, f1: 0.7516\n","loss: 0.3917, acc: 0.9673, test_acc: 0.8489, f1: 0.7678\n","loss: 0.3959, acc: 0.9665, test_acc: 0.8498, f1: 0.7792\n","loss: 0.3560, acc: 0.9706, test_acc: 0.8579, f1: 0.7966\n","loss: 0.3689, acc: 0.9741, test_acc: 0.8543, f1: 0.7952\n","loss: 0.3598, acc: 0.9771, test_acc: 0.8507, f1: 0.7906\n","loss: 0.3946, acc: 0.9789, test_acc: 0.8398, f1: 0.7537\n","loss: 0.3742, acc: 0.9808, test_acc: 0.8380, f1: 0.7418\n","loss: 0.3995, acc: 0.9803, test_acc: 0.8262, f1: 0.7200\n","loss: 0.5339, acc: 0.9741, test_acc: 0.8262, f1: 0.7238\n","loss: 0.3786, acc: 0.9762, test_acc: 0.8344, f1: 0.7441\n","loss: 0.4067, acc: 0.9754, test_acc: 0.8416, f1: 0.7662\n","loss: 0.2998, acc: 0.9769, test_acc: 0.8434, f1: 0.7734\n","loss: 0.3637, acc: 0.9780, test_acc: 0.8434, f1: 0.7712\n","loss: 0.4580, acc: 0.9750, test_acc: 0.8407, f1: 0.7630\n","loss: 0.4321, acc: 0.9728, test_acc: 0.8489, f1: 0.7736\n","loss: 0.3528, acc: 0.9743, test_acc: 0.8471, f1: 0.7649\n","loss: 0.4259, acc: 0.9738, test_acc: 0.8425, f1: 0.7623\n","loss: 0.4362, acc: 0.9730, test_acc: 0.8588, f1: 0.7907\n","loss: 0.3721, acc: 0.9744, test_acc: 0.8652, f1: 0.8033\n","loss: 0.3393, acc: 0.9755, test_acc: 0.8543, f1: 0.7745\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 11\n","loss: 0.3568, acc: 0.9615, test_acc: 0.8579, f1: 0.7861\n","loss: 0.4456, acc: 0.9444, test_acc: 0.8480, f1: 0.7764\n","loss: 0.3598, acc: 0.9643, test_acc: 0.8516, f1: 0.7838\n","loss: 0.3757, acc: 0.9744, test_acc: 0.8498, f1: 0.7745\n","loss: 0.4284, acc: 0.9718, test_acc: 0.8471, f1: 0.7658\n","loss: 0.3585, acc: 0.9763, test_acc: 0.8462, f1: 0.7642\n","loss: 0.3075, acc: 0.9795, test_acc: 0.8480, f1: 0.7763\n","loss: 0.3888, acc: 0.9825, test_acc: 0.8516, f1: 0.7868\n","loss: 0.4580, acc: 0.9771, test_acc: 0.8525, f1: 0.7848\n","loss: 0.3511, acc: 0.9758, test_acc: 0.8489, f1: 0.7703\n","loss: 0.4227, acc: 0.9749, test_acc: 0.8425, f1: 0.7490\n","loss: 0.4497, acc: 0.9715, test_acc: 0.8425, f1: 0.7391\n","loss: 0.3821, acc: 0.9710, test_acc: 0.8534, f1: 0.7732\n","loss: 0.3510, acc: 0.9711, test_acc: 0.8516, f1: 0.7765\n","loss: 0.4769, acc: 0.9683, test_acc: 0.8534, f1: 0.7823\n","loss: 0.4991, acc: 0.9654, test_acc: 0.8516, f1: 0.7763\n","loss: 0.3226, acc: 0.9671, test_acc: 0.8498, f1: 0.7706\n","loss: 0.3390, acc: 0.9686, test_acc: 0.8498, f1: 0.7662\n","loss: 0.4039, acc: 0.9685, test_acc: 0.8489, f1: 0.7663\n","loss: 0.3174, acc: 0.9703, test_acc: 0.8525, f1: 0.7776\n","loss: 0.3464, acc: 0.9719, test_acc: 0.8597, f1: 0.7936\n","loss: 0.3805, acc: 0.9714, test_acc: 0.8597, f1: 0.7814\n","loss: 0.3890, acc: 0.9694, test_acc: 0.8507, f1: 0.7638\n","loss: 0.2990, acc: 0.9705, test_acc: 0.8516, f1: 0.7751\n","loss: 0.3625, acc: 0.9717, test_acc: 0.8525, f1: 0.7786\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 12\n","loss: 0.4475, acc: 0.8800, test_acc: 0.8543, f1: 0.7771\n","loss: 0.3486, acc: 0.9434, test_acc: 0.8570, f1: 0.7754\n","loss: 0.3404, acc: 0.9620, test_acc: 0.8498, f1: 0.7575\n","loss: 0.4151, acc: 0.9519, test_acc: 0.8615, f1: 0.7845\n","loss: 0.2842, acc: 0.9615, test_acc: 0.8633, f1: 0.7925\n","loss: 0.3436, acc: 0.9688, test_acc: 0.8652, f1: 0.7963\n","loss: 0.3121, acc: 0.9730, test_acc: 0.8661, f1: 0.8000\n","loss: 0.3075, acc: 0.9765, test_acc: 0.8670, f1: 0.8005\n","loss: 0.3197, acc: 0.9795, test_acc: 0.8652, f1: 0.7967\n","loss: 0.3076, acc: 0.9822, test_acc: 0.8643, f1: 0.7958\n","loss: 0.3170, acc: 0.9838, test_acc: 0.8633, f1: 0.7940\n","loss: 0.3401, acc: 0.9853, test_acc: 0.8643, f1: 0.7954\n","loss: 0.3620, acc: 0.9838, test_acc: 0.8624, f1: 0.7911\n","loss: 0.3736, acc: 0.9825, test_acc: 0.8615, f1: 0.7861\n","loss: 0.3074, acc: 0.9839, test_acc: 0.8633, f1: 0.7890\n","loss: 0.2874, acc: 0.9846, test_acc: 0.8615, f1: 0.7959\n","loss: 0.2855, acc: 0.9854, test_acc: 0.8543, f1: 0.7920\n","loss: 0.3315, acc: 0.9862, test_acc: 0.8615, f1: 0.7972\n","loss: 0.3556, acc: 0.9850, test_acc: 0.8606, f1: 0.7922\n","loss: 0.3623, acc: 0.9840, test_acc: 0.8570, f1: 0.7867\n","loss: 0.3726, acc: 0.9832, test_acc: 0.8516, f1: 0.7749\n","loss: 0.3323, acc: 0.9839, test_acc: 0.8543, f1: 0.7832\n","loss: 0.4014, acc: 0.9816, test_acc: 0.8661, f1: 0.8052\n","loss: 0.3605, acc: 0.9825, test_acc: 0.8624, f1: 0.8036\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 13\n","loss: 0.2972, acc: 1.0000, test_acc: 0.8615, f1: 0.8018\n","loss: 0.3111, acc: 1.0000, test_acc: 0.8633, f1: 0.8060\n","loss: 0.2992, acc: 1.0000, test_acc: 0.8624, f1: 0.7949\n","loss: 0.2977, acc: 1.0000, test_acc: 0.8624, f1: 0.7909\n","loss: 0.3172, acc: 0.9933, test_acc: 0.8606, f1: 0.7844\n","loss: 0.3470, acc: 0.9884, test_acc: 0.8606, f1: 0.7833\n","loss: 0.3454, acc: 0.9851, test_acc: 0.8633, f1: 0.7926\n","loss: 0.3298, acc: 0.9870, test_acc: 0.8597, f1: 0.7920\n","loss: 0.4039, acc: 0.9776, test_acc: 0.8633, f1: 0.7945\n","loss: 0.4337, acc: 0.9731, test_acc: 0.8552, f1: 0.7757\n","loss: 0.3037, acc: 0.9755, test_acc: 0.8516, f1: 0.7680\n","loss: 0.4011, acc: 0.9745, test_acc: 0.8534, f1: 0.7754\n","loss: 0.4432, acc: 0.9718, test_acc: 0.8643, f1: 0.7982\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8724_f1_0.8093\n","loss: 0.3126, acc: 0.9737, test_acc: 0.8724, f1: 0.8093\n","loss: 0.2598, acc: 0.9751, test_acc: 0.8679, f1: 0.8026\n","loss: 0.3609, acc: 0.9745, test_acc: 0.8661, f1: 0.7987\n","loss: 0.3459, acc: 0.9741, test_acc: 0.8670, f1: 0.7979\n","loss: 0.3591, acc: 0.9737, test_acc: 0.8543, f1: 0.7637\n","loss: 0.3222, acc: 0.9749, test_acc: 0.8597, f1: 0.7754\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8778_f1_0.8223\n","loss: 0.2665, acc: 0.9761, test_acc: 0.8778, f1: 0.8223\n","loss: 0.3436, acc: 0.9755, test_acc: 0.8706, f1: 0.8191\n","loss: 0.3362, acc: 0.9751, test_acc: 0.8624, f1: 0.8170\n","loss: 0.2567, acc: 0.9760, test_acc: 0.8697, f1: 0.8112\n","loss: 0.3884, acc: 0.9754, test_acc: 0.8579, f1: 0.7829\n","loss: 0.3280, acc: 0.9751, test_acc: 0.8624, f1: 0.7918\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 14\n","loss: 0.4479, acc: 0.9310, test_acc: 0.8661, f1: 0.8008\n","loss: 0.3159, acc: 0.9474, test_acc: 0.8697, f1: 0.8078\n","loss: 0.2828, acc: 0.9610, test_acc: 0.8724, f1: 0.8138\n","loss: 0.2932, acc: 0.9709, test_acc: 0.8706, f1: 0.8120\n","loss: 0.2728, acc: 0.9774, test_acc: 0.8697, f1: 0.8087\n","loss: 0.3366, acc: 0.9752, test_acc: 0.8697, f1: 0.8139\n","loss: 0.2789, acc: 0.9791, test_acc: 0.8661, f1: 0.8139\n","loss: 0.4306, acc: 0.9725, test_acc: 0.8697, f1: 0.8148\n","loss: 0.2947, acc: 0.9751, test_acc: 0.8661, f1: 0.8043\n","loss: 0.2818, acc: 0.9782, test_acc: 0.8597, f1: 0.7910\n","loss: 0.3084, acc: 0.9801, test_acc: 0.8552, f1: 0.7838\n","loss: 0.3452, acc: 0.9793, test_acc: 0.8579, f1: 0.7845\n","loss: 0.3525, acc: 0.9782, test_acc: 0.8498, f1: 0.7614\n","loss: 0.2721, acc: 0.9770, test_acc: 0.8389, f1: 0.7213\n","loss: 0.3392, acc: 0.9766, test_acc: 0.8425, f1: 0.7352\n","loss: 0.2668, acc: 0.9780, test_acc: 0.8561, f1: 0.7726\n","loss: 0.3857, acc: 0.9752, test_acc: 0.8570, f1: 0.7826\n","loss: 0.3042, acc: 0.9767, test_acc: 0.8579, f1: 0.7904\n","loss: 0.3257, acc: 0.9779, test_acc: 0.8615, f1: 0.7914\n","loss: 0.2701, acc: 0.9792, test_acc: 0.8615, f1: 0.7895\n","loss: 0.2564, acc: 0.9804, test_acc: 0.8615, f1: 0.7851\n","loss: 0.3015, acc: 0.9812, test_acc: 0.8597, f1: 0.7871\n","loss: 0.2571, acc: 0.9819, test_acc: 0.8624, f1: 0.7946\n","loss: 0.3657, acc: 0.9810, test_acc: 0.8624, f1: 0.7966\n","loss: 0.3177, acc: 0.9805, test_acc: 0.8615, f1: 0.7940\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 15\n","loss: 0.2864, acc: 1.0000, test_acc: 0.8643, f1: 0.8042\n","loss: 0.4058, acc: 0.9667, test_acc: 0.8452, f1: 0.7827\n","loss: 0.3503, acc: 0.9588, test_acc: 0.8489, f1: 0.7868\n","loss: 0.3244, acc: 0.9600, test_acc: 0.8443, f1: 0.7675\n","loss: 0.3262, acc: 0.9615, test_acc: 0.8489, f1: 0.7718\n","loss: 0.2831, acc: 0.9677, test_acc: 0.8679, f1: 0.7973\n","loss: 0.3552, acc: 0.9686, test_acc: 0.8615, f1: 0.7856\n","loss: 0.2838, acc: 0.9720, test_acc: 0.8606, f1: 0.7828\n","loss: 0.2528, acc: 0.9746, test_acc: 0.8597, f1: 0.7871\n","loss: 0.2510, acc: 0.9777, test_acc: 0.8516, f1: 0.7794\n","loss: 0.2565, acc: 0.9773, test_acc: 0.8498, f1: 0.7839\n","loss: 0.2693, acc: 0.9792, test_acc: 0.8462, f1: 0.7862\n","loss: 0.2801, acc: 0.9807, test_acc: 0.8661, f1: 0.8139\n","loss: 0.3318, acc: 0.9798, test_acc: 0.8652, f1: 0.8002\n","loss: 0.2817, acc: 0.9812, test_acc: 0.8633, f1: 0.7887\n","loss: 0.2794, acc: 0.9820, test_acc: 0.8670, f1: 0.7988\n","loss: 0.4147, acc: 0.9774, test_acc: 0.8661, f1: 0.7983\n","loss: 0.3942, acc: 0.9749, test_acc: 0.8588, f1: 0.7815\n","loss: 0.2552, acc: 0.9758, test_acc: 0.8615, f1: 0.7874\n","loss: 0.2527, acc: 0.9771, test_acc: 0.8679, f1: 0.8042\n","loss: 0.3435, acc: 0.9766, test_acc: 0.8633, f1: 0.7973\n","loss: 0.2577, acc: 0.9759, test_acc: 0.8606, f1: 0.7859\n","loss: 0.3855, acc: 0.9741, test_acc: 0.8498, f1: 0.7536\n","loss: 0.3145, acc: 0.9736, test_acc: 0.8389, f1: 0.7303\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 16\n","loss: 0.3793, acc: 0.9333, test_acc: 0.8398, f1: 0.7328\n","loss: 0.3299, acc: 0.9538, test_acc: 0.8425, f1: 0.7397\n","loss: 0.2986, acc: 0.9570, test_acc: 0.8489, f1: 0.7554\n","loss: 0.2727, acc: 0.9669, test_acc: 0.8597, f1: 0.7826\n","loss: 0.2634, acc: 0.9655, test_acc: 0.8534, f1: 0.7762\n","loss: 0.2209, acc: 0.9699, test_acc: 0.8633, f1: 0.7980\n","loss: 0.3779, acc: 0.9639, test_acc: 0.8615, f1: 0.8034\n","loss: 0.2386, acc: 0.9686, test_acc: 0.8606, f1: 0.7901\n","loss: 0.2517, acc: 0.9712, test_acc: 0.8525, f1: 0.7576\n","loss: 0.2988, acc: 0.9699, test_acc: 0.8570, f1: 0.7698\n","loss: 0.2450, acc: 0.9729, test_acc: 0.8760, f1: 0.8191\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8796_f1_0.8273\n","loss: 0.3632, acc: 0.9695, test_acc: 0.8796, f1: 0.8273\n","loss: 0.2391, acc: 0.9723, test_acc: 0.8787, f1: 0.8257\n","loss: 0.3360, acc: 0.9713, test_acc: 0.8787, f1: 0.8192\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8805_f1_0.8204\n","loss: 0.2730, acc: 0.9729, test_acc: 0.8805, f1: 0.8204\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8842_f1_0.8265\n","loss: 0.2734, acc: 0.9746, test_acc: 0.8842, f1: 0.8265\n","loss: 0.2709, acc: 0.9743, test_acc: 0.8833, f1: 0.8269\n","loss: 0.2345, acc: 0.9756, test_acc: 0.8833, f1: 0.8304\n","loss: 0.2203, acc: 0.9770, test_acc: 0.8824, f1: 0.8298\n","loss: 0.2773, acc: 0.9784, test_acc: 0.8842, f1: 0.8320\n","loss: 0.3552, acc: 0.9778, test_acc: 0.8787, f1: 0.8229\n","loss: 0.2221, acc: 0.9791, test_acc: 0.8670, f1: 0.8003\n","loss: 0.2633, acc: 0.9800, test_acc: 0.8588, f1: 0.7842\n","loss: 0.2591, acc: 0.9809, test_acc: 0.8615, f1: 0.7878\n","loss: 0.2591, acc: 0.9818, test_acc: 0.8606, f1: 0.7844\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 17\n","loss: 0.2654, acc: 0.9600, test_acc: 0.8561, f1: 0.7802\n","loss: 0.2614, acc: 0.9821, test_acc: 0.8480, f1: 0.7685\n","loss: 0.1899, acc: 0.9870, test_acc: 0.8480, f1: 0.7658\n","loss: 0.3000, acc: 0.9815, test_acc: 0.8471, f1: 0.7609\n","loss: 0.2454, acc: 0.9857, test_acc: 0.8489, f1: 0.7649\n","loss: 0.2555, acc: 0.9820, test_acc: 0.8507, f1: 0.7713\n","loss: 0.3295, acc: 0.9786, test_acc: 0.8534, f1: 0.7768\n","loss: 0.4203, acc: 0.9667, test_acc: 0.8525, f1: 0.7755\n","loss: 0.2648, acc: 0.9712, test_acc: 0.8489, f1: 0.7675\n","loss: 0.2184, acc: 0.9745, test_acc: 0.8489, f1: 0.7680\n","loss: 0.2726, acc: 0.9767, test_acc: 0.8498, f1: 0.7692\n","loss: 0.3034, acc: 0.9756, test_acc: 0.8552, f1: 0.7765\n","loss: 0.2070, acc: 0.9774, test_acc: 0.8588, f1: 0.7823\n","loss: 0.2117, acc: 0.9789, test_acc: 0.8597, f1: 0.7833\n","loss: 0.3111, acc: 0.9778, test_acc: 0.8597, f1: 0.7861\n","loss: 0.2928, acc: 0.9795, test_acc: 0.8606, f1: 0.7881\n","loss: 0.2672, acc: 0.9806, test_acc: 0.8615, f1: 0.7891\n","loss: 0.3131, acc: 0.9798, test_acc: 0.8615, f1: 0.7894\n","loss: 0.2922, acc: 0.9791, test_acc: 0.8633, f1: 0.7954\n","loss: 0.2211, acc: 0.9803, test_acc: 0.8579, f1: 0.7869\n","loss: 0.2029, acc: 0.9813, test_acc: 0.8597, f1: 0.7887\n","loss: 0.2772, acc: 0.9807, test_acc: 0.8643, f1: 0.7990\n","loss: 0.2726, acc: 0.9800, test_acc: 0.8588, f1: 0.7903\n","loss: 0.2266, acc: 0.9809, test_acc: 0.8579, f1: 0.7856\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 18\n","loss: 0.2007, acc: 1.0000, test_acc: 0.8498, f1: 0.7608\n","loss: 0.4597, acc: 0.9508, test_acc: 0.8507, f1: 0.7623\n","loss: 0.2293, acc: 0.9667, test_acc: 0.8443, f1: 0.7614\n","loss: 0.2187, acc: 0.9737, test_acc: 0.8317, f1: 0.7611\n","loss: 0.2466, acc: 0.9792, test_acc: 0.8507, f1: 0.7807\n","loss: 0.2129, acc: 0.9822, test_acc: 0.8480, f1: 0.7729\n","loss: 0.2211, acc: 0.9848, test_acc: 0.8425, f1: 0.7624\n","loss: 0.2141, acc: 0.9867, test_acc: 0.8416, f1: 0.7564\n","loss: 0.3123, acc: 0.9805, test_acc: 0.8507, f1: 0.7759\n","loss: 0.2456, acc: 0.9825, test_acc: 0.8661, f1: 0.8147\n","loss: 0.1954, acc: 0.9842, test_acc: 0.8661, f1: 0.8076\n","loss: 0.3021, acc: 0.9823, test_acc: 0.8516, f1: 0.7740\n","loss: 0.3407, acc: 0.9785, test_acc: 0.8579, f1: 0.7922\n","loss: 0.2891, acc: 0.9774, test_acc: 0.8606, f1: 0.7998\n","loss: 0.3363, acc: 0.9744, test_acc: 0.8543, f1: 0.7870\n","loss: 0.2231, acc: 0.9761, test_acc: 0.8543, f1: 0.7839\n","loss: 0.2825, acc: 0.9757, test_acc: 0.8543, f1: 0.7807\n","loss: 0.2975, acc: 0.9754, test_acc: 0.8543, f1: 0.7801\n","loss: 0.2105, acc: 0.9765, test_acc: 0.8516, f1: 0.7740\n","loss: 0.3141, acc: 0.9760, test_acc: 0.8561, f1: 0.7815\n","loss: 0.2444, acc: 0.9773, test_acc: 0.8434, f1: 0.7607\n","loss: 0.2899, acc: 0.9768, test_acc: 0.8389, f1: 0.7493\n","loss: 0.1994, acc: 0.9780, test_acc: 0.8380, f1: 0.7432\n","loss: 0.3192, acc: 0.9762, test_acc: 0.8389, f1: 0.7388\n","loss: 0.2970, acc: 0.9760, test_acc: 0.8452, f1: 0.7565\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n","epoch: 19\n","loss: 0.1919, acc: 1.0000, test_acc: 0.8480, f1: 0.7685\n","loss: 0.3636, acc: 0.9706, test_acc: 0.8489, f1: 0.7692\n","loss: 0.2441, acc: 0.9800, test_acc: 0.8525, f1: 0.7691\n","loss: 0.2351, acc: 0.9845, test_acc: 0.8552, f1: 0.7677\n","loss: 0.2283, acc: 0.9874, test_acc: 0.8507, f1: 0.7595\n","loss: 0.3199, acc: 0.9787, test_acc: 0.8552, f1: 0.7700\n","loss: 0.1923, acc: 0.9817, test_acc: 0.8561, f1: 0.7832\n","loss: 0.1997, acc: 0.9843, test_acc: 0.8489, f1: 0.7725\n","loss: 0.2570, acc: 0.9820, test_acc: 0.8561, f1: 0.7787\n","loss: 0.2172, acc: 0.9837, test_acc: 0.8516, f1: 0.7619\n","loss: 0.1931, acc: 0.9851, test_acc: 0.8480, f1: 0.7545\n","loss: 0.3519, acc: 0.9806, test_acc: 0.8398, f1: 0.7403\n","loss: 0.2192, acc: 0.9819, test_acc: 0.8452, f1: 0.7523\n","loss: 0.2161, acc: 0.9830, test_acc: 0.8525, f1: 0.7692\n","loss: 0.2778, acc: 0.9817, test_acc: 0.8552, f1: 0.7743\n","loss: 0.2696, acc: 0.9807, test_acc: 0.8552, f1: 0.7719\n","loss: 0.3507, acc: 0.9779, test_acc: 0.8570, f1: 0.7773\n","loss: 0.1925, acc: 0.9790, test_acc: 0.8552, f1: 0.7751\n","loss: 0.1957, acc: 0.9801, test_acc: 0.8534, f1: 0.7738\n","loss: 0.2063, acc: 0.9811, test_acc: 0.8489, f1: 0.7792\n","loss: 0.2934, acc: 0.9804, test_acc: 0.8425, f1: 0.7738\n","loss: 0.2001, acc: 0.9812, test_acc: 0.8516, f1: 0.7802\n","loss: 0.2705, acc: 0.9807, test_acc: 0.8534, f1: 0.7799\n","loss: 0.2531, acc: 0.9800, test_acc: 0.8534, f1: 0.7736\n","loss: 0.2788, acc: 0.9794, test_acc: 0.8344, f1: 0.7344\n","max_test_acc: 0.8841628959276018, max_f1: 0.8320215660755222\n",">> saved: ./state_dict/EHFB_restaurant_acc_0.8842_f1_0.8265\n","############################################################\n","max_test_acc_overall:0.8841628959276018\n","max_f1_overall:0.8320215660755222\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"KnRmED5PA9Ku"},"execution_count":null,"outputs":[]}]}